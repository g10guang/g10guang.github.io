---
layout: post
title:  "开发软件和小脚本的区别"
date:   2018-01-20 09:00:05 +0800
categories: 心得
---

近日开发了一个武汉理工大学抢课软件，断断续续开发该软件花了不少时间，[Github仓库](https://github.com/g10guang/WHUT_Courses_System)

**以下是本文的小定义：**

+ 小脚本：容错性很差，是给专门人使用的，需要使用人对脚本逻辑有一定了解，比如Python脚本
+ 软件：开放给大众使用，需要提供好的 UI，需要很好的容错性，需要反馈给用户信息

如果只是供笔者用于的小脚本，完成抢课逻辑并不需要多少的代码量，可能几个小时分析问题，写几十行小脚本就完事了。但是我萌生了一个开发一个帮助同学抢课的软件，免得同学在抢课时分候着电脑、手机、平板点点点，最后却什么都没得到。

项目中需要爬取选课系统中的信息，就需要用到了爬虫，于是我屁颠屁颠地邀请懂爬虫的友人参与我的开发中。

我是平常研究的后端开发比较多，但是软件需要提供用户 UI，于是我匆匆忙忙地学习了TkInter的基本用法，随机开始了设计UI，由于不熟悉，开发过程也是不断地Google。很快用户界面开发得差不多了，但是由于Python的GIL存在的，为了提供用户体验，不让界面一卡一卡的，我又去研究了Python的多进程以及多线程（PS：采用的思路是抢课任务分配到新进程中进行，而且每添加一个新的任务就创建新的线程去执行）


其后爬虫的第一个方案似乎出了点问题，而且使用了Scrapy对于本项目有点笨重，笔者后面就去学了 requests+BeautifulSoup 作为简单的爬虫，去爬取特定的信息，requests模拟登陆拿到响应的html页面，BeautifulSoup 解析页面提取相关信息。

由于学校选课网站是外包项目，html写得非常凌乱（还有注释~~），每个选课的表格还不一样，还要为专门为某个选课做特殊处理。（可能这就是选课系统的防爬虫的措施吧~~）

幸好，requests与BeatifulSoup都提供了良好的文档和API，整个爬虫开发从学习到完成也就是花了两天时间而已。但是依然无法做到百分百的覆盖，我只能说爬虫在非抢课期间能够成功执行，但是如果在真正抢课期间，选课系统随时宕机，爬虫也就无法保证一定能正确无误地抓去数据。

怎么样能够提升用于体验，提供用户真正需要的功能，这确实是需要大量的思考。这也就是为什么腾讯、知乎等企业招聘员工要求应聘者需要有产品sense。

整个过程下来，感觉开发一个给予大众使用的软件成本非常高，怪不得web中要强调前后端分离，这样才能够做到前端能够注重用户体验，后端能够专注业务逻辑。整个团队的开发效率才会有所提升，术业有专攻，也不需要有那么一群人每个人都精通所有，（即使是前端也有专注与写JS逻辑、CSS样式）但付出的就是沟通成本。

**最后思考：**

一个网站防爬虫是多么重要，之前看朋友爬美团、携程的数据非常有趣，真实显示的数据与HTML中的数据相差是非常大的，他们之间有一些转换规则，或者是显示的价格是从图片中一个一个数字扣下来的，用心良苦，这给爬虫爬取有用的信息带来了很大的难度。有兴趣的朋友可以去尝试一下。

之前老师上课说真正项目中有一大半代码都是防御型代码，为了保证代码的鲁棒性。

如果这个世界每个人都那么遵守规则，这个社会做锁的成本会低了多少。
